{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13478985,"sourceType":"datasetVersion","datasetId":8557440},{"sourceId":13479291,"sourceType":"datasetVersion","datasetId":8557646},{"sourceId":13582543,"sourceType":"datasetVersion","datasetId":8629207},{"sourceId":627800,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":472755,"modelId":488631}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install pandas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T15:21:00.173862Z","iopub.execute_input":"2025-10-23T15:21:00.174605Z","iopub.status.idle":"2025-10-23T15:21:05.116101Z","shell.execute_reply.started":"2025-10-23T15:21:00.174579Z","shell.execute_reply":"2025-10-23T15:21:05.115040Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Install RDKit if needed:\n# !pip install rdkit pandas\n\nimport pandas as pd\nfrom rdkit import Chem\nfrom rdkit.Chem import Descriptors\n\n# 1Ô∏è‚É£ Load the dataset\ndf = pd.read_csv(# Install RDKit if needed:\n# !pip install rdkit pandas\n\nimport pandas as pd\nfrom rdkit import Chem\nfrom rdkit.Chem import Descriptors\n\n# 1Ô∏è‚É£ Load the dataset\ndf = pd.read_csv(\"/kaggle/input/ddi-data/drugbank100.csv\")  # <-- change filename if needed\ndf_head = df.head()  # take first 5 rows\n\n# 2Ô∏è‚É£ Define a function to compute descriptors\ndef extract_descriptors(smiles):\n    mol = Chem.MolFromSmiles(smiles)\n    if mol is None:\n        return {\n            \"MolWt\": None,\n            \"LogP\": None,\n            \"HBA\": None,\n            \"HBD\": None,\n            \"TPSA\": None,\n            \"RotatableBonds\": None\n        }\n    return {\n        \"MolWt\": Descriptors.MolWt(mol),\n        \"LogP\": Descriptors.MolLogP(mol),\n        \"HBA\": Descriptors.NumHAcceptors(mol),\n        \"HBD\": Descriptors.NumHDonors(mol),\n        \"TPSA\": Descriptors.TPSA(mol),\n        \"RotatableBonds\": Descriptors.NumRotatableBonds(mol)\n    }\n\n# 3Ô∏è‚É£ Loop through first rows and print results\nfor i, row in df_head.iterrows():\n    desc1 = extract_descriptors(row[\"X1\"])\n    desc2 = extract_descriptors(row[\"X2\"])\n    \n    print(f\"\\n================ ROW {i+1} ================\")\n    print(f\"Drug 1 (ID: {row['ID1']}):\")\n    for k, v in desc1.items():\n        print(f\"  {k}: {v}\")\n    \n    print(f\"\\nDrug 2 (ID: {row['ID2']}):\")\n    for k, v in desc2.items():\n        print(f\"  {k}: {v}\")\n    print(\"=========================================\")\n)  # <-- change filename if needed\ndf_head = df.head()  # take first 5 rows\n\n# 2Ô∏è‚É£ Define a function to compute descriptors\ndef extract_descriptors(smiles):\n    mol = Chem.MolFromSmiles(smiles)\n    if mol is None:\n        return {\n            \"MolWt\": None,\n            \"LogP\": None,\n            \"HBA\": None,\n            \"HBD\": None,\n            \"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T15:21:20.808036Z","iopub.execute_input":"2025-10-23T15:21:20.808349Z","iopub.status.idle":"2025-10-23T15:21:20.818900Z","shell.execute_reply.started":"2025-10-23T15:21:20.808326Z","shell.execute_reply":"2025-10-23T15:21:20.817873Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_37/720532418.py\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    import pandas as pd\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (720532418.py, line 12)","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"# Install RDKit and pandas if needed\n!pip install rdkit pandas\n\nimport pandas as pd\nfrom rdkit import Chem\nfrom rdkit.Chem import Descriptors\n\n# 1Ô∏è‚É£ Load your dataset (replace with your file path)\ndf = pd.read_csv(\"/kaggle/input/ddi-data/drugbank100.csv\")  # adjust path as needed\ndf_head = df.head()  # take first 5 rows\nprint(df_head)\n        \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T15:34:07.844239Z","iopub.execute_input":"2025-10-23T15:34:07.844625Z","iopub.status.idle":"2025-10-23T15:34:12.314256Z","shell.execute_reply.started":"2025-10-23T15:34:07.844592Z","shell.execute_reply":"2025-10-23T15:34:12.313140Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: rdkit in /usr/local/lib/python3.11/dist-packages (2025.9.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rdkit) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rdkit) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rdkit) (2024.2.0)\n       ID1      ID2  Y                                                Map  \\\n0  DB04571  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n1  DB00855  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n2  DB09536  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n3  DB01600  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n4  DB09000  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n\n                                           X1  \\\n0         CC1=CC2=CC3=C(OC(=O)C=C3C)C(C)=C2O1   \n1                             NCC(=O)CCC(O)=O   \n2                                    O=[Ti]=O   \n3       CC(C(O)=O)C1=CC=C(S1)C(=O)C1=CC=CC=C1   \n4  CC(CN(C)C)CN1C2=CC=CC=C2SC2=C1C=C(C=C2)C#N   \n\n                                                  X2  Map1  \n0  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...     1  \n1  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...     1  \n2  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...     1  \n3  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...     1  \n4  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...     1  \n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Install RDKit and pandas if needed\n# !pip install rdkit pandas\n\nimport pandas as pd\nfrom rdkit import Chem\nfrom rdkit.Chem import Descriptors\n\n# 1Ô∏è‚É£ Load your dataset (replace with your file path)\ndf = pd.read_csv(\"/kaggle/input/ddi-data/drugbank100.csv\")  # adjust path as needed\ndf_head = df.head()  # take first 5 rows\n\n# 2Ô∏è‚É£ Function to extract molecular descriptors\ndef extract_descriptors(smiles):\n    mol = Chem.MolFromSmiles(smiles)\n    if mol is None:\n        return {\n            \"MolWt\": None,\n            \"LogP\": None,\n            \"HBA\": None,\n            \"HBD\": None,\n            \"TPSA\": None,\n            \"RotatableBonds\": None\n        }\n    return {\n        \"MolWt\": Descriptors.MolWt(mol),\n        \"LogP\": Descriptors.MolLogP(mol),\n        \"HBA\": Descriptors.NumHAcceptors(mol),\n        \"HBD\": Descriptors.NumHDonors(mol),\n        \"TPSA\": Descriptors.TPSA(mol),\n        \"RotatableBonds\": Descriptors.NumRotatableBonds(mol)\n    }\n\n# 3Ô∏è‚É£ Loop through first few rows and print descriptor values\nfor i, row in df_head.iterrows():\n    desc1 = extract_descriptors(row[\"X1\"])\n    desc2 = extract_descriptors(row[\"X2\"])\n    \n    print(f\"\\n================ ROW {i+1} ================\")\n    print(f\"Drug 1 (ID: {row['ID1']}):\")\n    for k, v in desc1.items():\n        print(f\"  {k}: {v}\")\n\n    print(f\"\\nDrug 2 (ID: {row['ID2']}):\")\n    for k, v in desc2.items():\n        print(f\"  {k}: {v}\")\n    print(\"=========================================\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T15:35:10.980263Z","iopub.execute_input":"2025-10-23T15:35:10.981592Z","iopub.status.idle":"2025-10-23T15:35:11.562534Z","shell.execute_reply.started":"2025-10-23T15:35:10.981548Z","shell.execute_reply":"2025-10-23T15:35:11.561259Z"}},"outputs":[{"name":"stdout","text":"\n================ ROW 1 ================\nDrug 1 (ID: DB04571):\n  MolWt: 228.24699999999996\n  LogP: 3.4644600000000025\n  HBA: 3\n  HBD: 0\n  TPSA: 43.35\n  RotatableBonds: 0\n\nDrug 2 (ID: DB00460):\n  MolWt: 718.8070000000002\n  LogP: 6.719240000000006\n  HBA: 9\n  HBD: 3\n  TPSA: 173.55999999999997\n  RotatableBonds: 9\n=========================================\n\n================ ROW 2 ================\nDrug 1 (ID: DB00855):\n  MolWt: 131.131\n  LogP: -0.6210000000000004\n  HBA: 3\n  HBD: 2\n  TPSA: 80.39000000000001\n  RotatableBonds: 4\n\nDrug 2 (ID: DB00460):\n  MolWt: 718.8070000000002\n  LogP: 6.719240000000006\n  HBA: 9\n  HBD: 3\n  TPSA: 173.55999999999997\n  RotatableBonds: 9\n=========================================\n\n================ ROW 3 ================\nDrug 1 (ID: DB09536):\n  MolWt: 79.865\n  LogP: -0.2401\n  HBA: 2\n  HBD: 0\n  TPSA: 34.14\n  RotatableBonds: 0\n\nDrug 2 (ID: DB00460):\n  MolWt: 718.8070000000002\n  LogP: 6.719240000000006\n  HBA: 9\n  HBD: 3\n  TPSA: 173.55999999999997\n  RotatableBonds: 9\n=========================================\n\n================ ROW 4 ================\nDrug 1 (ID: DB01600):\n  MolWt: 260.31399999999996\n  LogP: 3.167200000000001\n  HBA: 3\n  HBD: 1\n  TPSA: 54.37\n  RotatableBonds: 4\n\nDrug 2 (ID: DB00460):\n  MolWt: 718.8070000000002\n  LogP: 6.719240000000006\n  HBA: 9\n  HBD: 3\n  TPSA: 173.55999999999997\n  RotatableBonds: 9\n=========================================\n\n================ ROW 5 ================\nDrug 1 (ID: DB09000):\n  MolWt: 323.4650000000001\n  LogP: 4.358680000000004\n  HBA: 4\n  HBD: 0\n  TPSA: 30.27\n  RotatableBonds: 4\n\nDrug 2 (ID: DB00460):\n  MolWt: 718.8070000000002\n  LogP: 6.719240000000006\n  HBA: 9\n  HBD: 3\n  TPSA: 173.55999999999997\n  RotatableBonds: 9\n=========================================\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Install RDKit if needed\n# !pip install rdkit pandas\n\nimport pandas as pd\nfrom rdkit import Chem\nfrom rdkit.Chem import Descriptors, AllChem, DataStructs\n\n# 1Ô∏è‚É£ Load dataset\ndf = pd.read_csv(\"/kaggle/input/ddi-data/drugbank100.csv\")  # adjust path as needed\ndf_head = df.head()  # take first 5 rows\n\n# 2Ô∏è‚É£ Function to extract descriptors\ndef extract_descriptors(smiles):\n    mol = Chem.MolFromSmiles(smiles)\n    if mol is None:\n        return {\n            \"MolWt\": None,\n            \"LogP\": None,\n            \"HBA\": None,\n            \"HBD\": None,\n            \"TPSA\": None,\n            \"RotatableBonds\": None,\n            \"Fingerprint\": None\n        }\n    # compute Morgan fingerprint for similarity\n    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024)\n    return {\n        \"MolWt\": Descriptors.MolWt(mol),\n        \"LogP\": Descriptors.MolLogP(mol),\n        \"HBA\": Descriptors.NumHAcceptors(mol),\n        \"HBD\": Descriptors.NumHDonors(mol),\n        \"TPSA\": Descriptors.TPSA(mol),\n        \"RotatableBonds\": Descriptors.NumRotatableBonds(mol),\n        \"Fingerprint\": fp\n    }\n\n# 3Ô∏è‚É£ Loop through first rows, compute and print results\nfor i, row in df_head.iterrows():\n    desc1 = extract_descriptors(row[\"X1\"])\n    desc2 = extract_descriptors(row[\"X2\"])\n    \n    # Calculate fingerprint similarity (Tanimoto)\n    if desc1[\"Fingerprint\"] and desc2[\"Fingerprint\"]:\n        similarity = DataStructs.TanimotoSimilarity(desc1[\"Fingerprint\"], desc2[\"Fingerprint\"])\n    else:\n        similarity = None\n    \n    print(f\"\\n================ ROW {i+1} ================\")\n    print(f\"Drug 1 (ID: {row['ID1']}):\")\n    for k, v in desc1.items():\n        if k != \"Fingerprint\":\n            print(f\"  {k}: {v}\")\n\n    print(f\"\\nDrug 2 (ID: {row['ID2']}):\")\n    for k, v in desc2.items():\n        if k != \"Fingerprint\":\n            print(f\"  {k}: {v}\")\n\n    print(f\"\\nüîπ Fingerprint Similarity (Tanimoto): {similarity}\")\n    print(\"=========================================\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T15:37:04.016974Z","iopub.execute_input":"2025-10-23T15:37:04.017290Z","iopub.status.idle":"2025-10-23T15:37:04.648413Z","shell.execute_reply.started":"2025-10-23T15:37:04.017268Z","shell.execute_reply":"2025-10-23T15:37:04.647517Z"}},"outputs":[{"name":"stdout","text":"\n================ ROW 1 ================\nDrug 1 (ID: DB04571):\n  MolWt: 228.24699999999996\n  LogP: 3.4644600000000025\n  HBA: 3\n  HBD: 0\n  TPSA: 43.35\n  RotatableBonds: 0\n\nDrug 2 (ID: DB00460):\n  MolWt: 718.8070000000002\n  LogP: 6.719240000000006\n  HBA: 9\n  HBD: 3\n  TPSA: 173.55999999999997\n  RotatableBonds: 9\n\nüîπ Fingerprint Similarity (Tanimoto): 0.09183673469387756\n=========================================\n\n================ ROW 2 ================\nDrug 1 (ID: DB00855):\n  MolWt: 131.131\n  LogP: -0.6210000000000004\n  HBA: 3\n  HBD: 2\n  TPSA: 80.39000000000001\n  RotatableBonds: 4\n\nDrug 2 (ID: DB00460):\n  MolWt: 718.8070000000002\n  LogP: 6.719240000000006\n  HBA: 9\n  HBD: 3\n  TPSA: 173.55999999999997\n  RotatableBonds: 9\n\nüîπ Fingerprint Similarity (Tanimoto): 0.09302325581395349\n=========================================\n\n================ ROW 3 ================\nDrug 1 (ID: DB09536):\n  MolWt: 79.865\n  LogP: -0.2401\n  HBA: 2\n  HBD: 0\n  TPSA: 34.14\n  RotatableBonds: 0\n\nDrug 2 (ID: DB00460):\n  MolWt: 718.8070000000002\n  LogP: 6.719240000000006\n  HBA: 9\n  HBD: 3\n  TPSA: 173.55999999999997\n  RotatableBonds: 9\n\nüîπ Fingerprint Similarity (Tanimoto): 0.012345679012345678\n=========================================\n\n================ ROW 4 ================\nDrug 1 (ID: DB01600):\n  MolWt: 260.31399999999996\n  LogP: 3.167200000000001\n  HBA: 3\n  HBD: 1\n  TPSA: 54.37\n  RotatableBonds: 4\n\nDrug 2 (ID: DB00460):\n  MolWt: 718.8070000000002\n  LogP: 6.719240000000006\n  HBA: 9\n  HBD: 3\n  TPSA: 173.55999999999997\n  RotatableBonds: 9\n\nüîπ Fingerprint Similarity (Tanimoto): 0.06930693069306931\n=========================================\n\n================ ROW 5 ================\nDrug 1 (ID: DB09000):\n  MolWt: 323.4650000000001\n  LogP: 4.358680000000004\n  HBA: 4\n  HBD: 0\n  TPSA: 30.27\n  RotatableBonds: 4\n\nDrug 2 (ID: DB00460):\n  MolWt: 718.8070000000002\n  LogP: 6.719240000000006\n  HBA: 9\n  HBD: 3\n  TPSA: 173.55999999999997\n  RotatableBonds: 9\n\nüîπ Fingerprint Similarity (Tanimoto): 0.04310344827586207\n=========================================\n","output_type":"stream"},{"name":"stderr","text":"[15:37:04] DEPRECATION WARNING: please use MorganGenerator\n[15:37:04] DEPRECATION WARNING: please use MorganGenerator\n[15:37:04] DEPRECATION WARNING: please use MorganGenerator\n[15:37:04] DEPRECATION WARNING: please use MorganGenerator\n[15:37:04] DEPRECATION WARNING: please use MorganGenerator\n[15:37:04] DEPRECATION WARNING: please use MorganGenerator\n[15:37:04] DEPRECATION WARNING: please use MorganGenerator\n[15:37:04] DEPRECATION WARNING: please use MorganGenerator\n[15:37:04] DEPRECATION WARNING: please use MorganGenerator\n[15:37:04] DEPRECATION WARNING: please use MorganGenerator\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"/kaggle/input/ddi-daat2/aggregated_data.csv\")  # adjust path as needed\ndf_head = df.head()\nprint(df_head)# take first 5 rows\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T15:53:36.644921Z","iopub.execute_input":"2025-10-23T15:53:36.645238Z","iopub.status.idle":"2025-10-23T15:53:37.500212Z","shell.execute_reply.started":"2025-10-23T15:53:36.645213Z","shell.execute_reply":"2025-10-23T15:53:37.499278Z"}},"outputs":[{"name":"stdout","text":"       ID1      ID2  Y                                                Map  \\\n0  DB04571  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n1  DB00855  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n2  DB09536  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n3  DB01600  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n4  DB09000  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n\n                                           X1  \\\n0         CC1=CC2=CC3=C(OC(=O)C=C3C)C(C)=C2O1   \n1                             NCC(=O)CCC(O)=O   \n2                                    O=[Ti]=O   \n3       CC(C(O)=O)C1=CC=C(S1)C(=O)C1=CC=CC=C1   \n4  CC(CN(C)C)CN1C2=CC=CC=C2SC2=C1C=C(C=C2)C#N   \n\n                                                  X2  Map1  MolWt_1  MolWt_2  \\\n0  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...     1  228.247  718.807   \n1  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...     1  131.131  718.807   \n2  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...     1   79.865  718.807   \n3  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...     1  260.314  718.807   \n4  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...     1  323.465  718.807   \n\n    LogP_1   LogP_2  HBD_1  HBD_2  HBA_1  HBA_2  TPSA_1  TPSA_2  \\\n0  3.46446  6.71924      0      3      3      9   43.35  173.56   \n1 -0.62100  6.71924      2      3      3      9   80.39  173.56   \n2 -0.24010  6.71924      0      3      2      9   34.14  173.56   \n3  3.16720  6.71924      1      3      3      9   54.37  173.56   \n4  4.35868  6.71924      0      3      4      9   30.27  173.56   \n\n   RotatableBonds_1  RotatableBonds_2  Fingerprint_Similarity  \n0                 0                 9                0.090909  \n1                 4                 9                0.091954  \n2                 0                 9                0.012195  \n3                 4                 9                0.068627  \n4                 4                 9                0.042735  \n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"print(df_head[Y])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T15:56:24.488769Z","iopub.execute_input":"2025-10-23T15:56:24.489093Z","iopub.status.idle":"2025-10-23T15:56:24.499506Z","shell.execute_reply.started":"2025-10-23T15:56:24.489071Z","shell.execute_reply":"2025-10-23T15:56:24.498138Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/3485527965.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_head\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"],"ename":"NameError","evalue":"name 'Y' is not defined","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"# Install if needed:\n!pip install pandas scikit-learn seaborn matplotlib\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\nfrom sklearn.ensemble import RandomForestClassifier\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 1Ô∏è‚É£ Load your dataset\ndf = pd.read_csv(\"/kaggle/input/ddi-daat2/aggregated_data.csv\")   # <-- change filename\ndf = df.dropna(subset=[\"Y\"])  # drop rows missing Y\n\n# 2Ô∏è‚É£ Define feature and target columns\nfeature_cols = [\n    \"MolWt_1\", \"MolWt_2\",\n    \"LogP_1\", \"LogP_2\",\n    \"HBD_1\", \"HBD_2\",\n    \"HBA_1\", \"HBA_2\",\n    \"TPSA_1\", \"TPSA_2\",\n    \"RotatableBonds_1\", \"RotatableBonds_2\",\n    \"Fingerprint_Similarity\"\n]\n\nX = df[feature_cols]\ny = df[\"Y\"].astype(int)  # ensure categorical integer labels\n\n# 3Ô∏è‚É£ Standardize numerical features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# 4Ô∏è‚É£ Split train/test\nX_train, X_test, y_train, y_test = train_test_split(\n    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# ------------------------------\n# üîπ A. ANOVA F-score (for numeric vs multiclass)\n# ------------------------------\nanova_selector = SelectKBest(score_func=f_classif, k='all')\nanova_selector.fit(X_train, y_train)\nanova_scores = anova_selector.scores_\n\n# ------------------------------\n# üîπ B. Mutual Information (captures nonlinear relations)\n# ------------------------------\nmi_scores = mutual_info_classif(X_train, y_train, random_state=42)\n\n# ------------------------------\n# üîπ C. Random Forest Feature Importance\n# ------------------------------\nrf = RandomForestClassifier(n_estimators=300, random_state=42)\nrf.fit(X_train, y_train)\nrf_importances = rf.feature_importances_\n\n# ------------------------------\n# üß† Combine feature ranking results\n# ------------------------------\nfeature_importance = pd.DataFrame({\n    \"Feature\": feature_cols,\n    \"ANOVA_F\": anova_scores,\n    \"Mutual_Info\": mi_scores,\n    \"RF_Importance\": rf_importances\n}).set_index(\"Feature\")\n\n# Normalize scores for comparison\nfeature_importance = feature_importance.apply(lambda x: x / x.max())\n\n# Sort by Random Forest importance\nfeature_importance = feature_importance.sort_values(\"RF_Importance\", ascending=False)\nprint(\"\\n=== Feature Importance Ranking ===\")\nprint(feature_importance)\n\n# ------------------------------\n# üìä Visualization\n# ------------------------------\nplt.figure(figsize=(10, 6))\nsns.heatmap(feature_importance, annot=True, cmap=\"viridis\", cbar=False)\nplt.title(\"Feature Importance (Normalized)\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T15:59:50.196278Z","iopub.execute_input":"2025-10-23T15:59:50.196654Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load the dataset\ndf = pd.read_csv(\"/kaggle/input/ddi-daat2/aggregated_data.csv\")\n\n# Print the number of rows and columns\nprint(\"Rows:\", df.shape[0])\nprint(\"Columns:\", df.shape[1])\n\n# Optionally, preview the data\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T20:12:54.795714Z","iopub.execute_input":"2025-11-01T20:12:54.796019Z","iopub.status.idle":"2025-11-01T20:12:58.873747Z","shell.execute_reply.started":"2025-11-01T20:12:54.795969Z","shell.execute_reply":"2025-11-01T20:12:58.872767Z"}},"outputs":[{"name":"stdout","text":"Rows: 191808\nColumns: 20\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"       ID1      ID2  Y                                                Map  \\\n0  DB04571  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n1  DB00855  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n2  DB09536  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n3  DB01600  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n4  DB09000  DB00460  1  #Drug1 may increase the photosensitizing activ...   \n\n                                           X1  \\\n0         CC1=CC2=CC3=C(OC(=O)C=C3C)C(C)=C2O1   \n1                             NCC(=O)CCC(O)=O   \n2                                    O=[Ti]=O   \n3       CC(C(O)=O)C1=CC=C(S1)C(=O)C1=CC=CC=C1   \n4  CC(CN(C)C)CN1C2=CC=CC=C2SC2=C1C=C(C=C2)C#N   \n\n                                                  X2  Map1  MolWt_1  MolWt_2  \\\n0  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...     1  228.247  718.807   \n1  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...     1  131.131  718.807   \n2  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...     1   79.865  718.807   \n3  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...     1  260.314  718.807   \n4  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...     1  323.465  718.807   \n\n    LogP_1   LogP_2  HBD_1  HBD_2  HBA_1  HBA_2  TPSA_1  TPSA_2  \\\n0  3.46446  6.71924      0      3      3      9   43.35  173.56   \n1 -0.62100  6.71924      2      3      3      9   80.39  173.56   \n2 -0.24010  6.71924      0      3      2      9   34.14  173.56   \n3  3.16720  6.71924      1      3      3      9   54.37  173.56   \n4  4.35868  6.71924      0      3      4      9   30.27  173.56   \n\n   RotatableBonds_1  RotatableBonds_2  Fingerprint_Similarity  \n0                 0                 9                0.090909  \n1                 4                 9                0.091954  \n2                 0                 9                0.012195  \n3                 4                 9                0.068627  \n4                 4                 9                0.042735  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID1</th>\n      <th>ID2</th>\n      <th>Y</th>\n      <th>Map</th>\n      <th>X1</th>\n      <th>X2</th>\n      <th>Map1</th>\n      <th>MolWt_1</th>\n      <th>MolWt_2</th>\n      <th>LogP_1</th>\n      <th>LogP_2</th>\n      <th>HBD_1</th>\n      <th>HBD_2</th>\n      <th>HBA_1</th>\n      <th>HBA_2</th>\n      <th>TPSA_1</th>\n      <th>TPSA_2</th>\n      <th>RotatableBonds_1</th>\n      <th>RotatableBonds_2</th>\n      <th>Fingerprint_Similarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DB04571</td>\n      <td>DB00460</td>\n      <td>1</td>\n      <td>#Drug1 may increase the photosensitizing activ...</td>\n      <td>CC1=CC2=CC3=C(OC(=O)C=C3C)C(C)=C2O1</td>\n      <td>COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...</td>\n      <td>1</td>\n      <td>228.247</td>\n      <td>718.807</td>\n      <td>3.46446</td>\n      <td>6.71924</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>9</td>\n      <td>43.35</td>\n      <td>173.56</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0.090909</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DB00855</td>\n      <td>DB00460</td>\n      <td>1</td>\n      <td>#Drug1 may increase the photosensitizing activ...</td>\n      <td>NCC(=O)CCC(O)=O</td>\n      <td>COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...</td>\n      <td>1</td>\n      <td>131.131</td>\n      <td>718.807</td>\n      <td>-0.62100</td>\n      <td>6.71924</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>9</td>\n      <td>80.39</td>\n      <td>173.56</td>\n      <td>4</td>\n      <td>9</td>\n      <td>0.091954</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DB09536</td>\n      <td>DB00460</td>\n      <td>1</td>\n      <td>#Drug1 may increase the photosensitizing activ...</td>\n      <td>O=[Ti]=O</td>\n      <td>COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...</td>\n      <td>1</td>\n      <td>79.865</td>\n      <td>718.807</td>\n      <td>-0.24010</td>\n      <td>6.71924</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>9</td>\n      <td>34.14</td>\n      <td>173.56</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0.012195</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DB01600</td>\n      <td>DB00460</td>\n      <td>1</td>\n      <td>#Drug1 may increase the photosensitizing activ...</td>\n      <td>CC(C(O)=O)C1=CC=C(S1)C(=O)C1=CC=CC=C1</td>\n      <td>COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...</td>\n      <td>1</td>\n      <td>260.314</td>\n      <td>718.807</td>\n      <td>3.16720</td>\n      <td>6.71924</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>9</td>\n      <td>54.37</td>\n      <td>173.56</td>\n      <td>4</td>\n      <td>9</td>\n      <td>0.068627</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DB09000</td>\n      <td>DB00460</td>\n      <td>1</td>\n      <td>#Drug1 may increase the photosensitizing activ...</td>\n      <td>CC(CN(C)C)CN1C2=CC=CC=C2SC2=C1C=C(C=C2)C#N</td>\n      <td>COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...</td>\n      <td>1</td>\n      <td>323.465</td>\n      <td>718.807</td>\n      <td>4.35868</td>\n      <td>6.71924</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>9</td>\n      <td>30.27</td>\n      <td>173.56</td>\n      <td>4</td>\n      <td>9</td>\n      <td>0.042735</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\n# Load the dataset\ndf = pd.read_csv(\"/kaggle/input/ddi-daat2/aggregated_data.csv\")\n\n# Print column names\nprint(\"Column names:\")\nprint(df.columns.tolist())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T20:13:22.588958Z","iopub.execute_input":"2025-11-01T20:13:22.589899Z","iopub.status.idle":"2025-11-01T20:13:23.459549Z","shell.execute_reply.started":"2025-11-01T20:13:22.589856Z","shell.execute_reply":"2025-11-01T20:13:23.458512Z"}},"outputs":[{"name":"stdout","text":"Column names:\n['ID1', 'ID2', 'Y', 'Map', 'X1', 'X2', 'Map1', 'MolWt_1', 'MolWt_2', 'LogP_1', 'LogP_2', 'HBD_1', 'HBD_2', 'HBA_1', 'HBA_2', 'TPSA_1', 'TPSA_2', 'RotatableBonds_1', 'RotatableBonds_2', 'Fingerprint_Similarity']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\n\n# Load your dataset\ndf = pd.read_csv(\"/kaggle/input/ddi-daat2/aggregated_data.csv\")\n\n# Check missing values count for each column\nprint(\"üîç Missing values per column:\")\nprint(df.isnull().sum())\n\n# Optional: total missing count\nprint(\"\\nTotal missing values in dataset:\", df.isna().sum().sum())\n\n# Optional: percentage of missing data per column\nprint(\"\\nPercentage of missing values per column:\")\nprint((df.isnull().mean() * 100).round(2))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T20:23:48.846244Z","iopub.execute_input":"2025-11-01T20:23:48.846557Z","iopub.status.idle":"2025-11-01T20:23:49.829323Z","shell.execute_reply.started":"2025-11-01T20:23:48.846531Z","shell.execute_reply":"2025-11-01T20:23:49.828298Z"}},"outputs":[{"name":"stdout","text":"üîç Missing values per column:\nID1                       0\nID2                       0\nY                         0\nMap                       0\nX1                        0\nX2                        0\nMap1                      0\nMolWt_1                   0\nMolWt_2                   0\nLogP_1                    0\nLogP_2                    0\nHBD_1                     0\nHBD_2                     0\nHBA_1                     0\nHBA_2                     0\nTPSA_1                    0\nTPSA_2                    0\nRotatableBonds_1          0\nRotatableBonds_2          0\nFingerprint_Similarity    0\ndtype: int64\n\nTotal missing values in dataset: 0\n\nPercentage of missing values per column:\nID1                       0.0\nID2                       0.0\nY                         0.0\nMap                       0.0\nX1                        0.0\nX2                        0.0\nMap1                      0.0\nMolWt_1                   0.0\nMolWt_2                   0.0\nLogP_1                    0.0\nLogP_2                    0.0\nHBD_1                     0.0\nHBD_2                     0.0\nHBA_1                     0.0\nHBA_2                     0.0\nTPSA_1                    0.0\nTPSA_2                    0.0\nRotatableBonds_1          0.0\nRotatableBonds_2          0.0\nFingerprint_Similarity    0.0\ndtype: float64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\n\n# Load the dataset\ndf = pd.read_csv(\"/kaggle/input/ddi-daat2/aggregated_data.csv\")\n\n# Print data types of each column\nprint(\"üìä Data types of each column:\")\nprint(df.dtypes)\n\n# Optional: get a summary of numeric and object columns\nprint(\"\\nNumeric columns:\", df.select_dtypes(include=['int64', 'float64']).columns.tolist())\nprint(\"Categorical columns:\", df.select_dtypes(include=['object']).columns.tolist())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T20:24:17.896873Z","iopub.execute_input":"2025-11-01T20:24:17.897216Z","iopub.status.idle":"2025-11-01T20:24:18.683404Z","shell.execute_reply.started":"2025-11-01T20:24:17.897190Z","shell.execute_reply":"2025-11-01T20:24:18.682336Z"}},"outputs":[{"name":"stdout","text":"üìä Data types of each column:\nID1                        object\nID2                        object\nY                           int64\nMap                        object\nX1                         object\nX2                         object\nMap1                        int64\nMolWt_1                   float64\nMolWt_2                   float64\nLogP_1                    float64\nLogP_2                    float64\nHBD_1                       int64\nHBD_2                       int64\nHBA_1                       int64\nHBA_2                       int64\nTPSA_1                    float64\nTPSA_2                    float64\nRotatableBonds_1            int64\nRotatableBonds_2            int64\nFingerprint_Similarity    float64\ndtype: object\n\nNumeric columns: ['Y', 'Map1', 'MolWt_1', 'MolWt_2', 'LogP_1', 'LogP_2', 'HBD_1', 'HBD_2', 'HBA_1', 'HBA_2', 'TPSA_1', 'TPSA_2', 'RotatableBonds_1', 'RotatableBonds_2', 'Fingerprint_Similarity']\nCategorical columns: ['ID1', 'ID2', 'Map', 'X1', 'X2']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\n\n# Load dataset\ndf = pd.read_csv(\"/kaggle/input/ddi-daat2/aggregated_data.csv\")\n\n# Drop 'Map' and 'Map1' columns\ndf = df.drop(columns=['Map', 'Map1'], errors='ignore')\n\n# Confirm removal\nprint(\"‚úÖ Columns removed successfully.\")\nprint(\"Remaining columns:\\n\", df.columns.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T20:27:31.724357Z","iopub.execute_input":"2025-11-01T20:27:31.724709Z","iopub.status.idle":"2025-11-01T20:27:32.485113Z","shell.execute_reply.started":"2025-11-01T20:27:31.724682Z","shell.execute_reply":"2025-11-01T20:27:32.484136Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Columns removed successfully.\nRemaining columns:\n ['ID1', 'ID2', 'Y', 'X1', 'X2', 'MolWt_1', 'MolWt_2', 'LogP_1', 'LogP_2', 'HBD_1', 'HBD_2', 'HBA_1', 'HBA_2', 'TPSA_1', 'TPSA_2', 'RotatableBonds_1', 'RotatableBonds_2', 'Fingerprint_Similarity']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Separate target and features\nX = df.drop(columns=['Y'])\ny = df['Y']\n\nprint(\"‚úÖ Target variable set successfully!\")\nprint(\"Features shape:\", X.shape)\nprint(\"Target shape:\", y.shape)\n\n# Optional: preview\nprint(\"\\nSample features:\")\nprint(X.head())\n\nprint(\"\\nSample target values:\")\nprint(y.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T20:38:43.170235Z","iopub.execute_input":"2025-11-01T20:38:43.171036Z","iopub.status.idle":"2025-11-01T20:38:43.203711Z","shell.execute_reply.started":"2025-11-01T20:38:43.170989Z","shell.execute_reply":"2025-11-01T20:38:43.202668Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Target variable set successfully!\nFeatures shape: (191808, 17)\nTarget shape: (191808,)\n\nSample features:\n       ID1      ID2                                          X1  \\\n0  DB04571  DB00460         CC1=CC2=CC3=C(OC(=O)C=C3C)C(C)=C2O1   \n1  DB00855  DB00460                             NCC(=O)CCC(O)=O   \n2  DB09536  DB00460                                    O=[Ti]=O   \n3  DB01600  DB00460       CC(C(O)=O)C1=CC=C(S1)C(=O)C1=CC=CC=C1   \n4  DB09000  DB00460  CC(CN(C)C)CN1C2=CC=CC=C2SC2=C1C=C(C=C2)C#N   \n\n                                                  X2  MolWt_1  MolWt_2  \\\n0  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...  228.247  718.807   \n1  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...  131.131  718.807   \n2  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...   79.865  718.807   \n3  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...  260.314  718.807   \n4  COC(=O)CCC1=C2NC(\\C=C3/N=C(/C=C4\\N\\C(=C/C5=N/C...  323.465  718.807   \n\n    LogP_1   LogP_2  HBD_1  HBD_2  HBA_1  HBA_2  TPSA_1  TPSA_2  \\\n0  3.46446  6.71924      0      3      3      9   43.35  173.56   \n1 -0.62100  6.71924      2      3      3      9   80.39  173.56   \n2 -0.24010  6.71924      0      3      2      9   34.14  173.56   \n3  3.16720  6.71924      1      3      3      9   54.37  173.56   \n4  4.35868  6.71924      0      3      4      9   30.27  173.56   \n\n   RotatableBonds_1  RotatableBonds_2  Fingerprint_Similarity  \n0                 0                 9                0.090909  \n1                 4                 9                0.091954  \n2                 0                 9                0.012195  \n3                 4                 9                0.068627  \n4                 4                 9                0.042735  \n\nSample target values:\n0    1\n1    1\n2    1\n3    1\n4    1\nName: Y, dtype: int64\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\n\n# ---------------------------------------------\n# 1Ô∏è‚É£ Drop ID and name columns\n# ---------------------------------------------\ndf_clean = df.drop(columns=['ID1', 'ID2', 'X1', 'X2'], errors='ignore')\n\n# Separate features and target\nX = df_clean.drop(columns=['Y'])\ny = df_clean['Y']\n\n# ---------------------------------------------\n# 2Ô∏è‚É£ ANOVA F-test (linear relationships)\n# ---------------------------------------------\nanova_selector = SelectKBest(score_func=f_classif, k='all')\nanova_selector.fit(X, y)\n\nanova_scores = pd.DataFrame({\n    'Feature': X.columns,\n    'ANOVA_F_Score': anova_selector.scores_\n}).sort_values(by='ANOVA_F_Score', ascending=False)\n\nprint(\"üìà Top features by ANOVA F-test (after removing IDs):\")\nprint(anova_scores.head(10))\n\n# ---------------------------------------------\n# 3Ô∏è‚É£ Mutual Information (non-linear relationships)\n# ---------------------------------------------\nmi_scores = mutual_info_classif(X, y, random_state=42)\nmi_scores_df = pd.DataFrame({\n    'Feature': X.columns,\n    'Mutual_Info_Score': mi_scores\n}).sort_values(by='Mutual_Info_Score', ascending=False)\n\nprint(\"\\nüîó Top features by Mutual Information:\")\nprint(mi_scores_df.head(10))\n\n# ---------------------------------------------\n# 4Ô∏è‚É£ Random Forest Importance\n# ---------------------------------------------\nrf = RandomForestClassifier(random_state=42)\nrf.fit(X, y)\n\nrf_importances = pd.DataFrame({\n    'Feature': X.columns,\n    'RF_Importance': rf.feature_importances_\n}).sort_values(by='RF_Importance', ascending=False)\n\nprint(\"\\nüå≤ Top features by Random Forest Importance:\")\nprint(rf_importances.head(10))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T21:50:43.530206Z","iopub.execute_input":"2025-11-01T21:50:43.531198Z","iopub.status.idle":"2025-11-01T21:52:35.955088Z","shell.execute_reply.started":"2025-11-01T21:50:43.531155Z","shell.execute_reply":"2025-11-01T21:52:35.954013Z"}},"outputs":[{"name":"stdout","text":"üìà Top features by ANOVA F-test (after removing IDs):\n   Feature  ANOVA_F_Score\n3   LogP_2     452.114213\n2   LogP_1     393.770237\n4    HBD_1     365.395246\n8   TPSA_1     344.908538\n7    HBA_2     321.090578\n6    HBA_1     305.932353\n1  MolWt_2     304.677533\n0  MolWt_1     256.712822\n9   TPSA_2     240.865706\n5    HBD_2     239.730950\n\nüîó Top features by Mutual Information:\n             Feature  Mutual_Info_Score\n3             LogP_2           1.384987\n1            MolWt_2           1.364830\n2             LogP_1           1.353233\n0            MolWt_1           1.336926\n9             TPSA_2           1.168265\n8             TPSA_1           1.141277\n6              HBA_1           0.180954\n11  RotatableBonds_2           0.173862\n7              HBA_2           0.168416\n10  RotatableBonds_1           0.161282\n\nüå≤ Top features by Random Forest Importance:\n                   Feature  RF_Importance\n1                  MolWt_2       0.109612\n3                   LogP_2       0.107206\n0                  MolWt_1       0.098439\n9                   TPSA_2       0.097626\n2                   LogP_1       0.096891\n8                   TPSA_1       0.094242\n12  Fingerprint_Similarity       0.082623\n11        RotatableBonds_2       0.070238\n10        RotatableBonds_1       0.063532\n7                    HBA_2       0.052094\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nimport pickle\n\n# =========================================\n# 1Ô∏è‚É£ Load your dataset\n# =========================================\ndf = pd.read_csv(\"/kaggle/input/ddi-daat2/aggregated_data.csv\")\n\n# Remove unnecessary ID columns\ndf_clean = df[['Y', \n               'MolWt_1', 'MolWt_2',\n               'LogP_1', 'LogP_2',\n               'HBD_1', 'HBD_2',\n               'HBA_1', 'HBA_2',\n               'TPSA_1', 'TPSA_2',\n               'Fingerprint_Similarity']].copy()\n\n# =========================================\n# 2Ô∏è‚É£ Prepare features and target\n# =========================================\nX = df_clean.drop(columns=['Y'])\ny = df_clean['Y']\n\n# Split dataset\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# =========================================\n# 3Ô∏è‚É£ Train Random Forest Classifier\n# =========================================\nrf = RandomForestClassifier(\n    n_estimators=300,\n    max_depth=None,\n    random_state=42,\n    n_jobs=-1\n)\nrf.fit(X_train, y_train)\n\n# Evaluate accuracy\nacc = rf.score(X_test, y_test)\nprint(f\"‚úÖ Model trained successfully! Accuracy: {acc:.4f}\")\n\n# =========================================\n# 4Ô∏è‚É£ Save trained model\n# =========================================\nmodel_path = \"/kaggle/working/ddi_rf_model.pkl\"\nwith open(model_path, 'wb') as file:\n    pickle.dump(rf, file)\n\nprint(f\"üíæ Model saved successfully at: {model_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T22:04:45.101059Z","iopub.execute_input":"2025-11-01T22:04:45.101226Z","iopub.status.idle":"2025-11-01T22:06:30.883379Z","shell.execute_reply.started":"2025-11-01T22:04:45.101209Z","shell.execute_reply":"2025-11-01T22:06:30.882309Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Model trained successfully! Accuracy: 0.8263\nüíæ Model saved successfully at: /kaggle/working/ddi_rf_model.pkl\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Create a download link\nFileLink(\"/kaggle/working/ddi_rf_model.pkl\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T22:06:30.892459Z","iopub.execute_input":"2025-11-01T22:06:30.892623Z","iopub.status.idle":"2025-11-01T22:06:30.908254Z","shell.execute_reply.started":"2025-11-01T22:06:30.892601Z","shell.execute_reply":"2025-11-01T22:06:30.907395Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/ddi_rf_model.pkl","text/html":"<a href='/kaggle/working/ddi_rf_model.pkl' target='_blank'>/kaggle/working/ddi_rf_model.pkl</a><br>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"pip install rdkit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T22:10:59.766558Z","iopub.execute_input":"2025-11-01T22:10:59.766908Z","iopub.status.idle":"2025-11-01T22:11:04.035302Z","shell.execute_reply.started":"2025-11-01T22:10:59.766886Z","shell.execute_reply":"2025-11-01T22:11:04.034193Z"}},"outputs":[{"name":"stdout","text":"Collecting rdkit\n  Downloading rdkit-2025.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/site-packages (from rdkit) (2.3.3)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.12/site-packages (from rdkit) (11.3.0)\nDownloading rdkit-2025.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (36.2 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m36.2/36.2 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rdkit\nSuccessfully installed rdkit-2025.9.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# =========================================\n# üì¶ Imports\n# =========================================\nimport pickle\nimport pandas as pd\nfrom rdkit import Chem\nfrom rdkit.Chem import Descriptors, rdMolDescriptors, DataStructs\nfrom rdkit.Chem.AllChem import GetMorganFingerprintAsBitVect\n\n# =========================================\n# 1Ô∏è‚É£ Load trained model\n# =========================================\nwith open(\"ddi_rf_model.pkl\", \"rb\") as file:\n    model = pickle.load(file)\n\nprint(\"‚úÖ Model loaded successfully!\")\n\n# =========================================\n# 2Ô∏è‚É£ Feature extraction function\n# =========================================\ndef extract_features_from_smiles(smile1, smile2):\n    mol1 = Chem.MolFromSmiles(smile1)\n    mol2 = Chem.MolFromSmiles(smile2)\n\n    if mol1 is None or mol2 is None:\n        raise ValueError(\"‚ùå Invalid SMILES string provided.\")\n\n    # Compute molecular descriptors\n    features = {\n        'MolWt_1': Descriptors.MolWt(mol1),\n        'MolWt_2': Descriptors.MolWt(mol2),\n        'LogP_1': Descriptors.MolLogP(mol1),\n        'LogP_2': Descriptors.MolLogP(mol2),\n        'HBD_1': rdMolDescriptors.CalcNumHBD(mol1),\n        'HBD_2': rdMolDescriptors.CalcNumHBD(mol2),\n        'HBA_1': rdMolDescriptors.CalcNumHBA(mol1),\n        'HBA_2': rdMolDescriptors.CalcNumHBA(mol2),\n        'TPSA_1': rdMolDescriptors.CalcTPSA(mol1),\n        'TPSA_2': rdMolDescriptors.CalcTPSA(mol2),\n    }\n\n    # Fingerprint similarity\n    fp1 = GetMorganFingerprintAsBitVect(mol1, 2, nBits=1024)\n    fp2 = GetMorganFingerprintAsBitVect(mol2, 2, nBits=1024)\n    features['Fingerprint_Similarity'] = DataStructs.TanimotoSimilarity(fp1, fp2)\n\n    return pd.DataFrame([features])\n\n# =========================================\n# 3Ô∏è‚É£ Predict from SMILES\n# =========================================\n# Example: replace with your own drug SMILES\ndrug1 = \"CCO\"         # ethanol\ndrug2 = \"CC(=O)O\"     # acetic acid\n\nfeatures = extract_features_from_smiles(drug1, drug2)\npredicted_class = model.predict(features)[0]\n\nprint(\"\\nüß™ Drug 1:\", drug1)\nprint(\"üß™ Drug 2:\", drug2)\nprint(\"üéØ Predicted Interaction Type:\", predicted_class)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T22:11:06.888706Z","iopub.execute_input":"2025-11-01T22:11:06.889050Z","iopub.status.idle":"2025-11-01T22:11:17.846753Z","shell.execute_reply.started":"2025-11-01T22:11:06.889030Z","shell.execute_reply":"2025-11-01T22:11:17.845668Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Model loaded successfully!\n\nüß™ Drug 1: CCO\nüß™ Drug 2: CC(=O)O\nüéØ Predicted Interaction Type: 16\n","output_type":"stream"},{"name":"stderr","text":"[22:11:17] DEPRECATION WARNING: please use MorganGenerator\n[22:11:17] DEPRECATION WARNING: please use MorganGenerator\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"pip install xgboost","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T22:12:59.652228Z","iopub.execute_input":"2025-11-01T22:12:59.652488Z","iopub.status.idle":"2025-11-01T22:13:17.357081Z","shell.execute_reply.started":"2025-11-01T22:12:59.652468Z","shell.execute_reply":"2025-11-01T22:13:17.356247Z"}},"outputs":[{"name":"stdout","text":"Collecting xgboost\n  Downloading xgboost-3.1.1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/site-packages (from xgboost) (2.3.3)\nCollecting nvidia-nccl-cu12 (from xgboost)\n  Downloading nvidia_nccl_cu12-2.28.7-py3-none-manylinux_2_18_x86_64.whl.metadata (2.0 kB)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/site-packages (from xgboost) (1.16.2)\nDownloading xgboost-3.1.1-py3-none-manylinux_2_28_x86_64.whl (115.9 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m115.9/115.9 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.28.7-py3-none-manylinux_2_18_x86_64.whl (296.8 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m296.8/296.8 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\nSuccessfully installed nvidia-nccl-cu12-2.28.7 xgboost-3.1.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nimport xgboost as xgb\nimport pickle\n\n# Load dataset\ndf = pd.read_csv(\"/kaggle/input/ddi-daat2/aggregated_data.csv\")\n\n# Use selected features\nX = df[['MolWt_1', 'MolWt_2', 'LogP_1', 'LogP_2',\n        'HBD_1', 'HBD_2', 'HBA_1', 'HBA_2',\n        'TPSA_1', 'TPSA_2', 'Fingerprint_Similarity']]\n\n# Shift class labels to start at 0\ny = df['Y'] - 1\n\n# Split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# Train model\nxgb_clf = xgb.XGBClassifier(\n    n_estimators=500,\n    max_depth=8,\n    learning_rate=0.05,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=42,\n    n_jobs=-1\n)\n\nxgb_clf.fit(X_train, y_train)\n\n# Evaluate\ny_pred = xgb_clf.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\n\nprint(f\"‚úÖ XGBoost Accuracy: {acc:.4f}\")\nprint(\"\\nüìä Classification Report:\")\nprint(classification_report(y_test, y_pred))\n\n# Save model\nmodel_path = \"/kaggle/working/ddi_xgb_model.pkl\"\nwith open(model_path, \"wb\") as file:\n    pickle.dump(xgb_clf, file)\n\nprint(f\"üíæ Model saved successfully: {model_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T22:19:13.657355Z","iopub.execute_input":"2025-11-01T22:19:13.657584Z","iopub.status.idle":"2025-11-01T22:22:58.894273Z","shell.execute_reply.started":"2025-11-01T22:19:13.657568Z","shell.execute_reply":"2025-11-01T22:22:58.893428Z"}},"outputs":[{"name":"stdout","text":"‚úÖ XGBoost Accuracy: 0.9120\n\nüìä Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      0.50      0.67         2\n           1       0.96      0.78      0.86        65\n           2       1.00      1.00      1.00       104\n           3       0.80      0.89      0.84      1002\n           4       0.95      0.87      0.91        62\n           5       0.94      0.96      0.95       632\n           6       1.00      1.00      1.00         4\n           7       0.76      0.80      0.78        49\n           8       0.97      0.96      0.96       422\n           9       0.90      0.95      0.93       126\n          10       0.82      0.44      0.57        62\n          11       0.93      0.83      0.88        48\n          12       1.00      0.67      0.80         9\n          13       1.00      1.00      1.00        72\n          14       0.85      0.85      0.85        40\n          15       0.92      0.97      0.95      1083\n          16       1.00      0.65      0.79        17\n          17       1.00      0.62      0.77        16\n          18       0.93      0.64      0.76        22\n          19       0.93      0.92      0.92      1228\n          20       0.98      1.00      0.99        86\n          21       0.86      1.00      0.93        19\n          22       1.00      0.64      0.78        11\n          23       1.00      0.97      0.99        36\n          24       0.97      0.97      0.97       143\n          25       1.00      1.00      1.00         1\n          26       0.99      0.97      0.98       187\n          27       1.00      1.00      1.00         2\n          28       1.00      0.88      0.93        65\n          29       0.84      0.75      0.79       123\n          30       1.00      0.67      0.80         3\n          31       0.87      0.97      0.92       202\n          32       0.90      0.53      0.67        88\n          33       0.94      0.94      0.94        62\n          34       0.70      0.50      0.58        14\n          35       0.82      0.74      0.78        19\n          36       0.97      0.96      0.97       618\n          37       1.00      0.71      0.83         7\n          38       1.00      1.00      1.00        30\n          39       0.98      1.00      0.99        60\n          40       0.67      0.67      0.67         3\n          41       1.00      1.00      1.00         1\n          42       0.00      0.00      0.00         2\n          43       0.00      0.00      0.00         2\n          44       1.00      1.00      1.00         6\n          45       1.00      0.80      0.89         5\n          46       0.88      0.93      0.90      6872\n          47       1.00      0.43      0.60        14\n          48       0.92      0.95      0.94     12150\n          49       0.67      0.40      0.50         5\n          50       1.00      1.00      1.00        17\n          51       0.00      0.00      0.00         2\n          52       0.93      0.63      0.75        67\n          53       0.97      0.91      0.94       255\n          54       0.96      0.92      0.94        24\n          55       1.00      0.33      0.50         6\n          56       0.95      0.91      0.93       133\n          57       0.92      1.00      0.96       209\n          58       0.82      1.00      0.90         9\n          59       0.93      0.90      0.91      1679\n          60       0.97      0.93      0.95       100\n          61       0.00      0.00      0.00         2\n          62       1.00      0.57      0.73         7\n          63       0.96      0.80      0.87       161\n          64       0.80      0.67      0.73         6\n          65       1.00      0.92      0.96        26\n          66       0.98      0.91      0.94       186\n          67       0.95      0.68      0.79        56\n          68       0.96      0.95      0.95        56\n          69       0.96      0.89      0.92      1557\n          70       0.97      0.86      0.91       135\n          71       0.97      0.98      0.97       365\n          72       0.89      0.83      0.86      4756\n          73       0.98      1.00      0.99        84\n          74       0.90      0.84      0.87      1894\n          75       0.93      0.98      0.96       112\n          76       0.92      0.76      0.83       108\n          77       1.00      0.80      0.89         5\n          78       1.00      0.60      0.75         5\n          79       0.80      0.62      0.70        13\n          80       0.95      0.95      0.95        22\n          81       0.94      0.85      0.89        71\n          82       0.99      0.98      0.98       241\n          83       0.90      0.69      0.78        13\n          84       0.90      0.70      0.79        74\n          85       1.00      0.80      0.89         5\n\n    accuracy                           0.91     38362\n   macro avg       0.89      0.79      0.83     38362\nweighted avg       0.91      0.91      0.91     38362\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n/usr/local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n/usr/local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n","output_type":"stream"},{"name":"stdout","text":"üíæ Model saved successfully: /kaggle/working/ddi_xgb_model.pkl\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch torch-geometric rdkit-pypi tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T23:35:03.528651Z","iopub.execute_input":"2025-11-01T23:35:03.528951Z","iopub.status.idle":"2025-11-01T23:36:25.167477Z","shell.execute_reply.started":"2025-11-01T23:35:03.528926Z","shell.execute_reply":"2025-11-01T23:36:25.166781Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nCollecting torch-geometric\n  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting rdkit-pypi\n  Downloading rdkit_pypi-2022.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.19.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.9.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.12.15)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (7.1.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.0.9)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.5)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.5.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (11.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.8.3)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-geometric) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rdkit_pypi-2022.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch-geometric, rdkit-pypi\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rdkit-pypi-2022.9.5 torch-geometric-2.7.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom rdkit import Chem\nfrom torch_geometric.data import Data\nfrom tqdm import tqdm\n\n# SMILES ‚Üí Graph converter\ndef smiles_to_graph(smiles):\n    mol = Chem.MolFromSmiles(smiles)\n    if mol is None:\n        return None\n\n    # Node features: atomic number, degree, formal charge, aromatic flag\n    x = []\n    for atom in mol.GetAtoms():\n        x.append([\n            atom.GetAtomicNum(),\n            atom.GetTotalDegree(),\n            atom.GetFormalCharge(),\n            int(atom.GetIsAromatic())\n        ])\n    x = torch.tensor(x, dtype=torch.float)\n\n    # Edge connections (bonds)\n    edge_index = []\n    for bond in mol.GetBonds():\n        i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n        edge_index.append([i, j])\n        edge_index.append([j, i])\n    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n\n    return Data(x=x, edge_index=edge_index)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T23:38:36.939778Z","iopub.execute_input":"2025-11-01T23:38:36.940078Z","iopub.status.idle":"2025-11-01T23:38:47.539238Z","shell.execute_reply.started":"2025-11-01T23:38:36.940051Z","shell.execute_reply":"2025-11-01T23:38:47.538505Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load your CSV\ndf = pd.read_csv(\"/kaggle/input/ddi-daat2/aggregated_data.csv\")\n\ngraph_pairs = []\nlabels = []\n\nprint(\"üöÄ Converting SMILES to molecular graphs...\")\nfor idx, row in tqdm(df.iterrows(), total=len(df)):\n    s1, s2, label = row['X1'], row['X2'], row['Y']\n    mol1 = smiles_to_graph(s1)\n    mol2 = smiles_to_graph(s2)\n    if mol1 is None or mol2 is None:\n        continue  # skip invalid SMILES\n\n    graph_pairs.append((mol1, mol2))\n    labels.append(int(label) - 1)  # shift to 0‚Äì85\n\n# Save processed dataset\ntorch.save({\n    'graph_pairs': graph_pairs,\n    'labels': torch.tensor(labels, dtype=torch.long)\n}, \"/kaggle/working/ddi_graph_dataset.pt\")\n\nprint(\"‚úÖ Dataset transformed and saved as '/kaggle/working/ddi_graph_dataset.pt'\")\nprint(f\"Total valid samples: {len(graph_pairs)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T00:19:23.760660Z","iopub.execute_input":"2025-11-02T00:19:23.761198Z","iopub.status.idle":"2025-11-02T00:24:05.492110Z","shell.execute_reply.started":"2025-11-02T00:19:23.761172Z","shell.execute_reply":"2025-11-02T00:24:05.491441Z"}},"outputs":[{"name":"stdout","text":"üöÄ Converting SMILES to molecular graphs...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 191808/191808 [03:58<00:00, 802.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Dataset transformed and saved as '/kaggle/working/ddi_graph_dataset.pt'\nTotal valid samples: 191808\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"pip install torch_geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T03:02:52.811949Z","iopub.execute_input":"2025-11-02T03:02:52.812202Z","iopub.status.idle":"2025-11-02T03:02:56.501478Z","shell.execute_reply.started":"2025-11-02T03:02:52.812184Z","shell.execute_reply":"2025-11-02T03:02:56.500482Z"}},"outputs":[{"name":"stdout","text":"Collecting torch_geometric\n  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/site-packages (from torch_geometric) (3.12.15)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/site-packages (from torch_geometric) (2025.9.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/site-packages (from torch_geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/site-packages (from torch_geometric) (2.3.3)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/site-packages (from torch_geometric) (7.1.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.12/site-packages (from torch_geometric) (3.3.0a1)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/site-packages (from torch_geometric) (2.32.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/site-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/site-packages (from torch_geometric) (3.6.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/site-packages (from aiohttp->torch_geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/site-packages (from aiohttp->torch_geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/site-packages (from aiohttp->torch_geometric) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/site-packages (from aiohttp->torch_geometric) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.20.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/site-packages (from jinja2->torch_geometric) (3.0.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests->torch_geometric) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/site-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests->torch_geometric) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests->torch_geometric) (2025.8.3)\nRequirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/site-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\nDownloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.7.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ======================================\n# üõ†Ô∏è Fix for PyTorch 2.6 UnpicklingError\n# ======================================\nimport torch\nfrom torch_geometric.data import Data\n\n# Allowlist the Data class so PyTorch can safely unpickle it\ntorch.serialization.add_safe_globals([Data])\n\n# Now load your dataset\ndata = torch.load(\"/kaggle/input/graph-ddi/ddi_graph_dataset.pt\", weights_only=False)\n\ngraph_pairs = data['graph_pairs']\nlabels = data['labels']\n\nprint(\"‚úÖ Dataset loaded successfully!\")\nprint(f\"Total samples: {len(graph_pairs)}\")\nprint(f\"Labels shape: {labels.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T03:03:01.427303Z","iopub.execute_input":"2025-11-02T03:03:01.427579Z","iopub.status.idle":"2025-11-02T03:03:48.244298Z","shell.execute_reply.started":"2025-11-02T03:03:01.427561Z","shell.execute_reply":"2025-11-02T03:03:48.243276Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Dataset loaded successfully!\nTotal samples: 191808\nLabels shape: torch.Size([191808])\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\nclass DDIGraphDataset(Dataset):\n    def __init__(self, graph_pairs, labels):\n        self.graph_pairs = graph_pairs\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        mol1, mol2 = self.graph_pairs[idx]\n        label = self.labels[idx]\n        return mol1, mol2, label\n\n# Create dataset objects\ndataset = DDIGraphDataset(graph_pairs, labels)\n\n# Train-test split\ntrain_size = int(0.8 * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n\n# Create loaders\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n\nprint(f\"‚úÖ DataLoader ready | Train: {len(train_dataset)} | Test: {len(test_dataset)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T03:05:34.631593Z","iopub.execute_input":"2025-11-02T03:05:34.632003Z","iopub.status.idle":"2025-11-02T03:05:34.657891Z","shell.execute_reply.started":"2025-11-02T03:05:34.631985Z","shell.execute_reply":"2025-11-02T03:05:34.657020Z"}},"outputs":[{"name":"stdout","text":"‚úÖ DataLoader ready | Train: 153446 | Test: 38362\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from torch_geometric.nn import GCNConv, global_mean_pool\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass GNNEncoder(nn.Module):\n    def __init__(self, input_dim=4, hidden_dim=64, embed_dim=128):\n        super(GNNEncoder, self).__init__()\n        self.conv1 = GCNConv(input_dim, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, embed_dim)\n\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        batch = getattr(data, \"batch\", torch.zeros(x.size(0), dtype=torch.long))\n        x = F.relu(self.conv1(x, edge_index))\n        x = F.relu(self.conv2(x, edge_index))\n        x = global_mean_pool(x, batch)\n        return x\n\n\nclass DDI_GNN(nn.Module):\n    def __init__(self, embed_dim=128, num_classes=86):\n        super(DDI_GNN, self).__init__()\n        self.encoder = GNNEncoder()\n        self.fc = nn.Sequential(\n            nn.Linear(embed_dim * 2, 256),\n            nn.ReLU(),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, mol1, mol2):\n        emb1 = self.encoder(mol1)\n        emb2 = self.encoder(mol2)\n        combined = torch.cat([emb1, emb2], dim=1)\n        return self.fc(combined)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T21:52:56.833689Z","iopub.execute_input":"2025-11-02T21:52:56.834008Z","iopub.status.idle":"2025-11-02T21:52:56.843688Z","shell.execute_reply.started":"2025-11-02T21:52:56.833985Z","shell.execute_reply":"2025-11-02T21:52:56.842531Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# =========================================\n# üì¶ Imports\n# =========================================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch_geometric.data import Data, Batch\nfrom torch_geometric.nn import GCNConv, global_mean_pool\n\n# =========================================\n# 1Ô∏è‚É£ Load Preprocessed Graph Dataset\n# =========================================\n# Allow safe unpickling of PyG Data objects (PyTorch 2.6+)\ntorch.serialization.add_safe_globals([Data])\n\ndata = torch.load(\"/kaggle/input/graph-ddi/ddi_graph_dataset.pt\", weights_only=False)\ngraph_pairs = data[\"graph_pairs\"]\nlabels = data[\"labels\"]\n\nprint(f\"‚úÖ Dataset loaded | Total samples: {len(graph_pairs)} | Labels shape: {labels.shape}\")\n\n# =========================================\n# 2Ô∏è‚É£ Define Custom Dataset\n# =========================================\nclass DDIGraphDataset(Dataset):\n    def __init__(self, graph_pairs, labels):\n        self.graph_pairs = graph_pairs\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        mol1, mol2 = self.graph_pairs[idx]\n        label = self.labels[idx]\n        return mol1, mol2, label\n\ndataset = DDIGraphDataset(graph_pairs, labels)\n\n# =========================================\n# 3Ô∏è‚É£ Train / Test Split\n# =========================================\ntrain_size = int(0.8 * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n\nprint(f\"üìä Train: {len(train_dataset)} | Test: {len(test_dataset)}\")\n\n# =========================================\n# 4Ô∏è‚É£ Custom Collate Function for Graph Pairs\n# =========================================\ndef ddi_collate_fn(batch):\n    mol1_list, mol2_list, label_list = zip(*batch)\n    mol1_batch = Batch.from_data_list(mol1_list)\n    mol2_batch = Batch.from_data_list(mol2_list)\n    labels = torch.tensor(label_list, dtype=torch.long)\n    return mol1_batch, mol2_batch, labels\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=ddi_collate_fn)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=ddi_collate_fn)\n\n# =========================================\n# 5Ô∏è‚É£ Define the GNN Model\n# =========================================\nclass GNNEncoder(nn.Module):\n    def __init__(self, input_dim=4, hidden_dim=64, embed_dim=128):\n        super(GNNEncoder, self).__init__()\n        self.conv1 = GCNConv(input_dim, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, embed_dim)\n\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        batch = getattr(data, \"batch\", torch.zeros(x.size(0), dtype=torch.long, device=x.device))\n        x = F.relu(self.conv1(x, edge_index))\n        x = F.relu(self.conv2(x, edge_index))\n        x = global_mean_pool(x, batch)\n        return x\n\nclass DDI_GNN(nn.Module):\n    def __init__(self, embed_dim=128, num_classes=86):\n        super(DDI_GNN, self).__init__()\n        self.encoder = GNNEncoder()\n        self.fc = nn.Sequential(\n            nn.Linear(embed_dim * 2, 256),\n            nn.ReLU(),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, mol1, mol2):\n        emb1 = self.encoder(mol1)\n        emb2 = self.encoder(mol2)\n        combined = torch.cat([emb1, emb2], dim=1)\n        return self.fc(combined)\n\n# =========================================\n# 6Ô∏è‚É£ Training Setup\n# =========================================\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"‚úÖ Using device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n\nmodel = DDI_GNN().to(device)\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()\n\n\n# =========================================\n# 7Ô∏è‚É£ Training Loop\n# =========================================\nEPOCHS = 20 # increase to 20‚Äì30 for full training\n\nfor epoch in range(EPOCHS):\n    model.train()\n    total_loss = 0\n    for mol1, mol2, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n        mol1, mol2, labels = mol1.to(device), mol2.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(mol1, mol2)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Epoch [{epoch+1}/{EPOCHS}] | Loss: {avg_loss:.4f}\")\n\n# =========================================\n# 8Ô∏è‚É£ Save Model\n# =========================================\ntorch.save(model.state_dict(), \"/kaggle/working/ddi_gnn_model1.pt\")\nprint(\"üíæ GNN model saved successfully at /kaggle/working/ddi_gnn_model1.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T22:50:46.615660Z","iopub.execute_input":"2025-11-02T22:50:46.616005Z","iopub.status.idle":"2025-11-02T23:36:26.575167Z","shell.execute_reply.started":"2025-11-02T22:50:46.615981Z","shell.execute_reply":"2025-11-02T23:36:26.574101Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Dataset loaded | Total samples: 191808 | Labels shape: torch.Size([191808])\nüìä Train: 153446 | Test: 38362\n‚úÖ Using device: CPU\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:04<00:00, 77.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/20] | Loss: 2.2501\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:03<00:00, 77.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/20] | Loss: 1.9221\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:03<00:00, 77.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/20] | Loss: 1.7057\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:04<00:00, 77.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/20] | Loss: 1.5721\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:07<00:00, 75.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/20] | Loss: 1.4782\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:11<00:00, 72.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/20] | Loss: 1.4018\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:14<00:00, 71.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/20] | Loss: 1.3334\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:17<00:00, 69.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/20] | Loss: 1.2774\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:17<00:00, 69.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/20] | Loss: 1.2257\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:17<00:00, 69.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [10/20] | Loss: 1.1787\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:17<00:00, 69.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [11/20] | Loss: 1.1354\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:17<00:00, 69.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [12/20] | Loss: 1.0977\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:18<00:00, 69.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [13/20] | Loss: 1.0601\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:16<00:00, 70.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [14/20] | Loss: 1.0254\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:17<00:00, 69.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [15/20] | Loss: 0.9946\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:19<00:00, 68.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [16/20] | Loss: 0.9662\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:18<00:00, 69.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [17/20] | Loss: 0.9422\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:21<00:00, 67.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [18/20] | Loss: 0.9155\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:19<00:00, 68.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [19/20] | Loss: 0.8973\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9591/9591 [02:18<00:00, 69.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [20/20] | Loss: 0.8768\nüíæ GNN model saved successfully at /kaggle/working/ddi_gnn_model1.pt\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"pip install streamlit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T21:30:32.740621Z","iopub.execute_input":"2025-11-02T21:30:32.741325Z","iopub.status.idle":"2025-11-02T21:30:39.066691Z","shell.execute_reply.started":"2025-11-02T21:30:32.741292Z","shell.execute_reply":"2025-11-02T21:30:39.065497Z"}},"outputs":[{"name":"stdout","text":"Collecting streamlit\n  Downloading streamlit-1.51.0-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\nRequirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\nRequirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\nRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.3.0)\nRequirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\nRequirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\nRequirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.3)\nRequirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\nRequirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.20.3)\nRequirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (19.0.1)\nRequirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.5)\nRequirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\nRequirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\nRequirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.15.0)\nRequirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\nRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\nCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.5.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\nRequirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.0)\nRequirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (1.48.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->streamlit) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->streamlit) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->streamlit) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->streamlit) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->streamlit) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->streamlit) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.26.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.23->streamlit) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.23->streamlit) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.23->streamlit) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.23->streamlit) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.23->streamlit) (2024.2.0)\nDownloading streamlit-1.51.0-py3-none-any.whl (10.2 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pydeck, streamlit\nSuccessfully installed pydeck-0.9.1 streamlit-1.51.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"pip install rdkit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T21:31:08.098264Z","iopub.execute_input":"2025-11-02T21:31:08.098586Z","iopub.status.idle":"2025-11-02T21:31:15.674703Z","shell.execute_reply.started":"2025-11-02T21:31:08.098563Z","shell.execute_reply":"2025-11-02T21:31:15.673232Z"}},"outputs":[{"name":"stdout","text":"Collecting rdkit\n  Downloading rdkit-2025.9.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rdkit) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rdkit) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rdkit) (2024.2.0)\nDownloading rdkit-2025.9.1-cp311-cp311-manylinux_2_28_x86_64.whl (36.2 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m36.2/36.2 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rdkit\nSuccessfully installed rdkit-2025.9.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"pip install torch_geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T21:17:19.340948Z","iopub.execute_input":"2025-11-02T21:17:19.341612Z","iopub.status.idle":"2025-11-02T21:17:26.598823Z","shell.execute_reply.started":"2025-11-02T21:17:19.341576Z","shell.execute_reply":"2025-11-02T21:17:26.597604Z"}},"outputs":[{"name":"stdout","text":"Collecting torch_geometric\n  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.12.15)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.9.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (7.1.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.0.9)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.5.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.8.3)\nRequirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch_geometric) (2024.2.0)\nDownloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.7.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ==========================================\n# Load & Evaluate RF, XGBoost, and GNN Models\n# ==========================================\n\nimport torch\nimport pickle\nimport xgboost as xgb\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score,\n    f1_score, classification_report, confusion_matrix\n)\n\n# -----------------------------\n# Load Preprocessed Test Data\n# -----------------------------\n# Make sure X_test, y_test, and test_loader (for GNN) are already available\n# If not, load from your saved dataset or split your data again with the same random_state\n# Example (for reference):\n# from sklearn.model_selection import train_test_split\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# -----------------------------\n# Load Random Forest Model\n# -----------------------------\nrf_path = \"/kaggle/working/ddi_rf_model.pkl\"\nwith open(rf_path, 'rb') as file:\n    rf_model = pickle.load(file)\n\nrf_pred = rf_model.predict(X_test)\nrf_metrics = {\n    \"Model\": \"Random Forest\",\n    \"Accuracy\": accuracy_score(y_test, rf_pred),\n    \"Precision\": precision_score(y_test, rf_pred, average=\"weighted\", zero_division=0),\n    \"Recall\": recall_score(y_test, rf_pred, average=\"weighted\", zero_division=0),\n    \"F1\": f1_score(y_test, rf_pred, average=\"weighted\", zero_division=0)\n}\n\n# -----------------------------\n# Load XGBoost Model\n# -----------------------------\nxgb_path = \"/kaggle/working/ddi_xgb_model.json\"  # adjust if saved as .pkl or .model\nxgb_model = xgb.XGBClassifier()\nxgb_model.load_model(xgb_path)\n\nxgb_pred = xgb_model.predict(X_test)\nxgb_metrics = {\n    \"Model\": \"XGBoost\",\n    \"Accuracy\": accuracy_score(y_test, xgb_pred),\n    \"Precision\": precision_score(y_test, xgb_pred, average=\"weighted\", zero_division=0),\n    \"Recall\": recall_score(y_test, xgb_pred, average=\"weighted\", zero_division=0),\n    \"F1\": f1_score(y_test, xgb_pred, average=\"weighted\", zero_division=0)\n}\n\n# -----------------------------\n# Load GNN Model\n# -----------------------------\n# Define the GNN architecture used before training\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, global_mean_pool\n\nclass DDI_GNN_Model(nn.Module):\n    def __init__(self, num_features, hidden_dim, num_classes):\n        super(DDI_GNN_Model, self).__init__()\n        self.conv1 = GCNConv(num_features, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n        self.fc = nn.Linear(hidden_dim, num_classes)\n\n    def forward(self, x, edge_index, batch):\n        x = F.relu(self.conv1(x, edge_index))\n        x = F.dropout(x, p=0.3, training=self.training)\n        x = self.conv2(x, edge_index)\n        x = global_mean_pool(x, batch)\n        return self.fc(x)\n\n# Load model\ngnn_model = DDI_GNN_Model(num_features=128, hidden_dim=256, num_classes=86)  # adjust to your dataset\ngnn_model.load_state_dict(torch.load(\"/kaggle/working/ddi_gnn_model1.pt\", map_location=torch.device(\"cpu\")))\ngnn_model.eval()\n\n# Evaluate GNN\ngnn_preds, gnn_labels = [], []\nwith torch.no_grad():\n    for data in test_loader:\n        data = data.to('cpu')\n        out = gnn_model(data.x, data.edge_index, data.batch)\n        preds = out.argmax(dim=1)\n        gnn_preds.extend(preds.cpu().numpy())\n        gnn_labels.extend(data.y.cpu().numpy())\n\ngnn_metrics = {\n    \"Model\": \"GNN\",\n    \"Accuracy\": accuracy_score(gnn_labels, gnn_preds),\n    \"Precision\": precision_score(gnn_labels, gnn_preds, average=\"weighted\", zero_division=0),\n    \"Recall\": recall_score(gnn_labels, gnn_preds, average=\"weighted\", zero_division=0),\n    \"F1\": f1_score(gnn_labels, gnn_preds, average=\"weighted\", zero_division=0)\n}\n\n# -----------------------------\n# Combine Results\n# -----------------------------\nresults_df = pd.DataFrame([rf_metrics, xgb_metrics, gnn_metrics])\nprint(\"\\n==================== Model Comparison ====================\")\nprint(results_df)\n\n# -----------------------------\n# Detailed Reports (Optional)\n# -----------------------------\nprint(\"\\n----- Random Forest Report -----\")\nprint(classification_report(y_test, rf_pred))\n\nprint(\"\\n----- XGBoost Report -----\")\nprint(classification_report(y_test, xgb_pred))\n\nprint(\"\\n----- GNN Report -----\")\nprint(classification_report(gnn_labels, gnn_preds))\n\n# Confusion Matrix Example (XGBoost)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncm = confusion_matrix(y_test, xgb_pred)\nplt.figure(figsize=(10, 7))\nsns.heatmap(cm, cmap=\"Blues\", annot=False)\nplt.title(\"XGBoost Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}