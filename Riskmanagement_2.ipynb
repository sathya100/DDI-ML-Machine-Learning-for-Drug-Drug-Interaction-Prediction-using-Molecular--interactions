{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "254d8760-b649-45e8-8cb3-ed02aaa19575",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç DATA VALIDATION REPORT:\n",
      "  total_columns: 20\n",
      "  numeric_columns_checked: 15\n",
      "  missing_values: 0\n",
      "  duplicate_rows: 0\n",
      "  infinite_values: 0\n",
      "  outlier_count: 40160\n",
      "\n",
      "üìÇ SCHEMA CHECK REPORT:\n",
      "{'missing_columns': [], 'unexpected_columns': ['ID1', 'ID2', 'Map', 'X1', 'X2', 'Map1', 'RotatableBonds_1', 'RotatableBonds_2']}\n",
      "\n",
      "‚úÖ Cleaned dataset shape: (191808, 20)\n",
      "\n",
      "üìä DRIFT DETECTION REPORT (Mean/Std Ratio):\n",
      "  Y: 2.056\n",
      "  Map1: 0.197\n",
      "  MolWt_1: 0.243\n",
      "  MolWt_2: 0.294\n",
      "  LogP_1: 0.052\n",
      "  LogP_2: 0.036\n",
      "  HBD_1: 0.262\n",
      "  HBD_2: 0.2\n",
      "  HBA_1: 0.273\n",
      "  HBA_2: 0.242\n",
      "  TPSA_1: 0.27\n",
      "  TPSA_2: 0.276\n",
      "  RotatableBonds_1: 0.105\n",
      "  RotatableBonds_2: 0.173\n",
      "  Fingerprint_Similarity: 0.111\n",
      "\n",
      "‚ö†Ô∏è Potential drift detected in: ['Y']\n",
      "‚úîÔ∏è Technical Implementation Summary\n",
      "------------------------------------\n",
      "1. Data Validation: Checks numeric consistency, schema, and outliers safely.\n",
      "2. Drift Detection: Monitors feature distribution changes without errors.\n",
      "These strengthen Data Collection, Deployment, and Monitoring stages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# ‚úÖ FINAL VERSION ‚Äì Technical Implementations for Risk Management\n",
    "# ==========================================================\n",
    "# Author: Sathyadharini\n",
    "# Project: DDI Risk Strategy ‚Äì aggregated_data\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"aggregated_data.csv\")  # update if different\n",
    "\n",
    "# ==========================================================\n",
    "# TECHNICAL IMPLEMENTATION #1: DATA VALIDATION & SCHEMA CHECK\n",
    "# ==========================================================\n",
    "\n",
    "def validate_data(df):\n",
    "    \"\"\"\n",
    "    Validates only numeric columns and reports missing, duplicates, and outliers.\n",
    "    Ignores text fields such as SMILES or DB identifiers.\n",
    "    \"\"\"\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    report = {\n",
    "        \"total_columns\": len(df.columns),\n",
    "        \"numeric_columns_checked\": len(numeric_df.columns),\n",
    "        \"missing_values\": int(df.isnull().sum().sum()),\n",
    "        \"duplicate_rows\": int(df.duplicated().sum()),\n",
    "        \"infinite_values\": int(np.isinf(numeric_df).sum().sum())\n",
    "    }\n",
    "\n",
    "    # Calculate outliers only for numeric data\n",
    "    if not numeric_df.empty:\n",
    "        z_scores = (numeric_df - numeric_df.mean()) / (numeric_df.std() + 1e-6)\n",
    "        report[\"outlier_count\"] = int((abs(z_scores) > 3).sum().sum())\n",
    "    else:\n",
    "        report[\"outlier_count\"] = 0\n",
    "\n",
    "    return report, numeric_df\n",
    "\n",
    "\n",
    "def schema_check(df, expected_features):\n",
    "    \"\"\"\n",
    "    Verifies expected schema before deployment or model inference.\n",
    "    \"\"\"\n",
    "    missing = [col for col in expected_features if col not in df.columns]\n",
    "    extra = [col for col in df.columns if col not in expected_features]\n",
    "    return {\"missing_columns\": missing, \"unexpected_columns\": extra}\n",
    "\n",
    "\n",
    "expected_features = [\n",
    "    'MolWt_1', 'MolWt_2', 'LogP_1', 'LogP_2', 'HBD_1', 'HBD_2',\n",
    "    'HBA_1', 'HBA_2', 'TPSA_1', 'TPSA_2', 'Fingerprint_Similarity', 'Y'\n",
    "]\n",
    "\n",
    "# Run validation\n",
    "validation_report, numeric_df = validate_data(df)\n",
    "schema_report = schema_check(df, expected_features)\n",
    "\n",
    "print(\"üîç DATA VALIDATION REPORT:\")\n",
    "for k, v in validation_report.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "print(\"\\nüìÇ SCHEMA CHECK REPORT:\")\n",
    "print(schema_report)\n",
    "\n",
    "# Clean data (safe numeric fill)\n",
    "df[numeric_df.columns] = numeric_df.fillna(numeric_df.median())\n",
    "df = df.drop_duplicates()\n",
    "print(\"\\n‚úÖ Cleaned dataset shape:\", df.shape)\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# TECHNICAL IMPLEMENTATION #2: DATA DRIFT DETECTION\n",
    "# ==========================================================\n",
    "\n",
    "def detect_drift(old_df, new_df, column):\n",
    "    \"\"\"\n",
    "    Computes mean/std ratio difference to flag drift for numeric columns only.\n",
    "    \"\"\"\n",
    "    if column not in old_df.columns or column not in new_df.columns:\n",
    "        return np.nan\n",
    "    if not np.issubdtype(old_df[column].dtype, np.number):\n",
    "        return np.nan\n",
    "    drift_value = abs(old_df[column].mean() - new_df[column].mean()) / (old_df[column].std() + 1e-6)\n",
    "    return round(drift_value, 3)\n",
    "\n",
    "\n",
    "# Split data (simulate old vs new)\n",
    "split = int(len(df) * 0.7)\n",
    "old_data, new_data = df.iloc[:split], df.iloc[split:]\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "drift_report = {col: detect_drift(old_data, new_data, col) for col in numeric_cols}\n",
    "\n",
    "print(\"\\nüìä DRIFT DETECTION REPORT (Mean/Std Ratio):\")\n",
    "for feature, drift in drift_report.items():\n",
    "    print(f\"  {feature}: {drift}\")\n",
    "\n",
    "# Flag potential drifts\n",
    "high_drift = [col for col, value in drift_report.items() if value > 0.5]\n",
    "if high_drift:\n",
    "    print(\"\\n‚ö†Ô∏è Potential drift detected in:\", high_drift)\n",
    "else:\n",
    "    print(\"\\n‚úÖ No significant drift detected. Dataset stable.\")\n",
    "\n",
    "# ==========================================================\n",
    "# Summary\n",
    "# ==========================================================\n",
    "print(\"\"\"‚úîÔ∏è Technical Implementation Summary\n",
    "------------------------------------\n",
    "1. Data Validation: Checks numeric consistency, schema, and outliers safely.\n",
    "2. Drift Detection: Monitors feature distribution changes without errors.\n",
    "These strengthen Data Collection, Deployment, and Monitoring stages.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1064715-7bc2-4c8f-9620-d4bfb910ff3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
